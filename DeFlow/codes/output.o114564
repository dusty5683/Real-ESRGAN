Started
1
Test Python packages:

torch: 1.11.0
pillow: 9.0.1
numpy: 1.20.3
basicsr: 1.3.5
opencv-python: 4.5.5
tqdm: 4.64.0
scipy: 1.8.0
torchvision: 0.12.0
facexlib: 0.2.2
lmdb: 1.3.0
pyyaml: 6.0
yapf: 0.32.0

test tensor:
tensor([[0.4135, 0.0270, 0.3243],
        [0.2132, 0.3612, 0.9831],
        [0.4588, 0.4843, 0.1038],
        [0.1200, 0.6781, 0.2081],
        [0.7107, 0.6316, 0.0358]])

Is cuda avail:
True

Cuda version:
10.2
__CUDNN VERSION: 7605
__Number CUDA Devices: 1
__CUDA Device Name: Tesla V100-PCIE-16GB
__CUDA Device Total Memory [GB]: 16.945512448
Device:  cuda
Traceback (most recent call last):
  File "/bsuhome/dustinrobinson275/final/DeFlow/codes/translate.py", line 27, in <module>
    model = create_model(util.getPredictorOdict(os.path.join("confs/", args.opt), args.model_path))
  File "/bsuhome/dustinrobinson275/final/DeFlow/codes/models/__init__.py", line 51, in create_model
    m = M(opt, step)
  File "/bsuhome/dustinrobinson275/final/DeFlow/codes/models/SRFL_Glow_model.py", line 41, in __init__
    self.netG = DataParallel(self.netG)
  File "/bsuhome/dustinrobinson275/miniconda3/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py", line 145, in __init__
    self.module.to(self.src_device_obj)
  File "/bsuhome/dustinrobinson275/miniconda3/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/bsuhome/dustinrobinson275/miniconda3/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/bsuhome/dustinrobinson275/miniconda3/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/bsuhome/dustinrobinson275/miniconda3/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  [Previous line repeated 3 more times]
  File "/bsuhome/dustinrobinson275/miniconda3/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/bsuhome/dustinrobinson275/miniconda3/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 15.78 GiB total capacity; 85.89 MiB already allocated; 4.50 MiB free; 88.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
1
Finished
